{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Frame Overlap Tutorial (v0.2.0)\n\nThis tutorial demonstrates the frame_overlap package for analyzing neutron Time-of-Flight frame overlap data.\n\n## Overview\n\nThe package provides five main classes:\n\n1. **Data**: Load and process ToF data\n2. **Reconstruct**: Apply deconvolution filters\n3. **Analysis**: Simplified nbragg integration\n4. **Workflow**: High-level method chaining and parameter sweeps (NEW!)\n5. **ParametricScan**: Parameter sensitivity analysis\n\n## CORRECT Workflow Order:\n\n```\nData → Convolute → Poisson → Overlap → Reconstruct → Analysis\n        ↓           ↓          ↓          ↓           ↓\n    Instrument  Add noise  Frame ops  Recover     Fit with\n     response   (+ flux              signal      nbragg\n                scaling)\n```\n\n**KEY INSIGHT**: Convolute BEFORE Poisson!\n\nWhy? The pulse_duration defines the pulsed source duty cycle:\n- `effective_flux = flux × pulse_duration × freq`\n- Flux is measured for continuous source, but measurement is pulsed\n- Convolute stores pulse_duration, Poisson uses it automatically\n\n## New Features in v0.2.0:\n- **Workflow class**: Fluent API for method chaining entire pipeline\n- **Parameter sweeps**: `groupby()` for exploring parameter spaces with tqdm progress bars\n- **Automatic flux scaling** by pulse_duration in Poisson\n- **tmin/tmax filtering**: Calculate chi² on specific time/wavelength range\n- **Vertical indicators**: Show tmin/tmax on plots\n- **Two-subplot plotting**: Data + residuals in σ units\n- **nbragg integration**: `recon.to_nbragg()` for wavelength conversion\n- **Analysis class**: Clean API for nbragg fitting\n- **Noise optimization**: `recon.optimize_noise()` with lmfit"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from frame_overlap import Data, Reconstruct, Analysis\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load signal and openbeam data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = Data(\n",
    "    signal_file='iron_powder.csv',\n",
    "    openbeam_file='openbeam.csv',\n",
    "    flux=1e6,       # n/cm²/s (continuous source)\n",
    "    duration=1.0,   # hours\n",
    "    freq=20,        # Hz\n",
    "    threshold=0\n",
    ")\n",
    "\n",
    "print(data)\n",
    "print(f\"\\nLoaded {len(data.table)} data points\")\n",
    "print(f\"Time range: {data.table['time'].min():.1f} - {data.table['time'].max():.1f} µs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw data\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instrument Response Convolution (FIRST!)\n",
    "\n",
    "Apply convolution to simulate the instrument's pulse duration.\n",
    "\n",
    "**IMPORTANT**: This step stores `pulse_duration`, which will be used by `poisson_sample()` to calculate effective flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolute with 200 µs pulse\n",
    "data.convolute_response(pulse_duration=200)\n",
    "\n",
    "print(f\"Convolution applied with pulse_duration = {data.pulse_duration} µs\")\n",
    "print(f\"Data shape: {data.table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolved data\n",
    "data.plot(kind=\"signal\",show_stages=True, show_errors=False,ylim=(0,5e5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Poisson Sampling (AFTER Convolution!)\n",
    "\n",
    "Apply Poisson sampling to simulate neutron counting statistics.\n",
    "\n",
    "**Automatic flux scaling**: Since `pulse_duration` and `freq` are known, the effective flux is:\n",
    "```\n",
    "flux_eff = flux × (pulse_duration / 1e6) × freq\n",
    "         = 1e6 × (200e-6) × 20\n",
    "         = 4000 n/cm²/s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Poisson sampling\n",
    "# flux is automatically scaled by pulse_duration × freq\n",
    "data.poisson_sample(flux=1e6, measurement_time=240, freq=20)\n",
    "\n",
    "print(\"Poisson sampling applied\")\n",
    "print(f\"Data shape: {data.table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"transmission\",show_stages=True, show_errors=False,ylim=(0,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Frame Overlap\n",
    "\n",
    "Create overlapping frames. Example: `[0, 25]` means:\n",
    "- Frame 1 starts at t = 0 ms\n",
    "- Frame 2 starts at t = 25 ms\n",
    "\n",
    "**Optional**: Use `poisson_seed` to add randomness to the overlapped signal with duty_cycle=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2-frame overlap\n",
    "data.overlap(kernel=[0, 25], total_time=50)\n",
    "\n",
    "print(f\"Frame overlap created with kernel: {data.kernel}\")\n",
    "print(f\"  Frame 1 starts at: 0 ms\")\n",
    "print(f\"  Frame 2 starts at: 25 ms\")\n",
    "print(f\"New data length: {len(data.table)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overlapped data\n",
    "data.plot(kind=\"transmission\", show_errors=False,ylim=(0,1),xlim=(0,50))\n",
    "plt.title('Data after Frame Overlap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(kind=\"signal\",show_stages=True, show_errors=False,ylim=(0,5e3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Signal Reconstruction\n",
    "\n",
    "Apply deconvolution to recover the poissoned+convolved signal (before overlap).\n",
    "\n",
    "**NEW**: Specify `tmin` and `tmax` (in ms) to calculate chi² only on a specific time range!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Reconstruct object\n",
    "# Example with tmin/tmax: recon = Reconstruct(data, tmin=10, tmax=40)\n",
    "recon = Reconstruct(data,tmin=1,tmax=6)\n",
    "\n",
    "# Apply Wiener filter\n",
    "recon.filter(kind='wiener', noise_power=0.01)\n",
    "\n",
    "print(\"Reconstruction complete!\")\n",
    "print(f\"\\nWhat we recovered: Poissoned+Convolved signal (before overlap)\")\n",
    "print(f\"Reference shape: {recon.reference_data.shape}\")\n",
    "print(f\"Reconstructed shape: {recon.reconstructed_data.shape}\")\n",
    "\n",
    "print(f\"\\nReconstruction Statistics:\")\n",
    "for key, value in recon.get_statistics().items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Reconstruction\n",
    "\n",
    "Two-subplot layout:\n",
    "- **Top**: Poissoned+Convolved (target) vs Reconstructed\n",
    "- **Bottom**: Residuals in σ units\n",
    "\n",
    "**NEW**: Green/orange vertical lines show tmin/tmax if specified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot reconstruction results\n",
    "recon.plot(kind='transmission', show_errors=False,ylim=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot signal counts\n",
    "recon.plot(kind='signal', show_errors=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Noise Optimization\n",
    "\n",
    "Use `optimize_noise()` to find the optimal noise_power parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize noise parameter\n",
    "try:\n",
    "    result = recon.optimize_noise(\n",
    "        kind='wiener',\n",
    "        noise_min=1e-4,\n",
    "        noise_max=1.0,\n",
    "        method='leastsq'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nOptimal noise_power: {result.params['noise_power'].value:.4e}\")\n",
    "    print(f\"Chi-squared: {result.chisqr:.2f}\")\n",
    "    \n",
    "    # Plot optimized reconstruction\n",
    "    recon.plot(kind='transmission', show_errors=True,ylim=(0,1))\n",
    "    plt.suptitle(f\"Optimized (noise={result.params['noise_power'].value:.4e})\")\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"lmfit not installed - install with: pip install lmfit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. nbragg Integration\n",
    "\n",
    "Convert reconstructed data to nbragg format and fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to nbragg format\n",
    "nbragg_data = recon.to_nbragg(L=9.0, tstep=10e-6)\n",
    "print(f\"✓ Converted to nbragg.Data\")\n",
    "print(f\"  Type: {type(nbragg_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbragg_data.table.plot(x=\"wavelength\",y=\"trans\",ylim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analysis = Analysis(xs='iron', vary_background=True,vary_response=True)\n",
    "\n",
    "print(\"Analysis object created\")\n",
    "print(f\"Access nbragg model: analysis.model.params\")\n",
    "\n",
    "# Fit\n",
    "result = analysis.fit(recon)\n",
    "\n",
    "print(f\"\\nFit complete!\")\n",
    "print(f\"Reduced chi-squared: {result.redchi:.3f}\")\n",
    "\n",
    "# Plot\n",
    "analysis.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method Chaining\n",
    "\n",
    "Complete workflow in one chain with CORRECT order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method chaining with CORRECT order\n",
    "data_chain = (Data(signal_file='iron_powder.csv', \n",
    "                   openbeam_file='openbeam.csv',\n",
    "                   flux=1e6, duration=1.0, freq=20)\n",
    "              .convolute_response(200)              # 1. Convolute (stores pulse_duration)\n",
    "              .poisson_sample(flux=1e6,             # 2. Poisson (uses pulse_duration)\n",
    "                             measurement_time=1.0, \n",
    "                             freq=20)\n",
    "              .overlap([0, 25]))                    # 3. Overlap\n",
    "\n",
    "print(\"✓ Method chaining complete (CORRECT ORDER)\")\n",
    "print(data_chain)\n",
    "\n",
    "# Reconstruct with tmin/tmax filtering\n",
    "recon_chain = Reconstruct(data_chain, tmin=10, tmax=40).filter(kind='wiener', noise_power=0.01)\n",
    "chi2_formatted = recon_chain._format_chi2(recon_chain.statistics.get('chi2_per_dof'))\n",
    "print(f\"\\nχ²/dof (10-40 ms range): {chi2_formatted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 8. NEW: Workflow Class (v0.2.0)\n\nThe **Workflow** class provides a fluent API for chaining the entire pipeline in one expression.\n\n### Basic Usage"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from frame_overlap import Workflow\n\n# Simple workflow - complete pipeline in one chain\nwf = Workflow('iron_powder.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\n\nresult = (wf\n    .convolute(pulse_duration=200)\n    .poisson(flux=1e6, freq=60, measurement_time=30)\n    .overlap(kernel=[0, 25])\n    .reconstruct(kind='wiener', noise_power=0.01)\n    .analyze(xs='iron', vary_background=True, vary_response=True))\n\nprint(f\"Workflow: {wf}\")\nprint(f\"Analysis result: {wf.result}\")\n\n# Plot results\nwf.plot()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Parameter Sweeps with groupby()\n\nExplore parameter space to find optimal values. The `groupby()` method sets up a parameter sweep, and `run()` executes it with a progress bar.\n\n**Available parameters to sweep**:\n- `pulse_duration`: Pulse width in µs\n- `noise_power`: Wiener filter noise parameter\n- `flux`, `freq`, `duty_cycle`: Poisson sampling parameters\n- Any reconstruction or analysis parameter"
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n\n**CORRECT Processing Order**: Data → **Convolute** → **Poisson** → Overlap → Reconstruct → Analysis\n\n### Three Ways to Use the Package:\n\n#### 1. Step-by-Step (Full Control)\n```python\ndata = Data('signal.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\ndata.convolute_response(200)\ndata.poisson_sample(flux=1e6, freq=60, measurement_time=30)\ndata.overlap([0, 25])\nrecon = Reconstruct(data, tmin=10, tmax=40)\nrecon.filter(kind='wiener', noise_power=0.01)\nanalysis = Analysis(xs='iron')\nresult = analysis.fit(recon)\n```\n\n#### 2. Method Chaining (Data class)\n```python\ndata = (Data('signal.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\n        .convolute_response(200)\n        .poisson_sample(flux=1e6, freq=60, measurement_time=30)\n        .overlap([0, 25]))\nrecon = Reconstruct(data).filter(kind='wiener', noise_power=0.01)\n```\n\n#### 3. Workflow (Complete Pipeline + Sweeps) - NEW!\n```python\n# Simple processing\nwf = Workflow('signal.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\nresult = (wf.convolute(200).poisson(1e6, 60, 30).overlap([0, 25])\n           .reconstruct('wiener', noise_power=0.01)\n           .analyze(xs='iron'))\n\n# Parameter optimization\nresults = (wf.groupby('noise_power', 0.01, 0.1, num=20)\n            .reconstruct('wiener').analyze(xs='iron').run())\n```\n\n### Key Points:\n1. **Convolute FIRST** to define pulse_duration\n2. **Poisson SECOND** uses pulse_duration for flux scaling:\n   - `duty_cycle = (flux_new / flux_orig) × freq × pulse_duration`\n3. **Overlap THIRD** creates overlapped frames\n4. **Reconstruction** recovers poissoned+convolved signal (before overlap)\n5. **Workflow** provides the most convenient API for exploration and optimization\n\n### NEW v0.2.0 Features:\n- ✨ **Workflow class**: Complete pipeline in one fluent chain\n- 📊 **Parameter sweeps**: `groupby()` with automatic progress bars\n- 🎯 **Smart error handling**: Sweeps continue even if individual runs fail\n- 📈 **Rich results**: DataFrame with chi², AIC, BIC, and all fitted parameters\n- 🔧 Automatic pulse_duration scaling in Poisson\n- 📏 tmin/tmax for chi² range filtering\n- 📍 Vertical indicators on plots\n- 🔗 `recon.to_nbragg()` for wavelength conversion\n- 🎛️ `recon.optimize_noise()` with lmfit\n- 🧪 Analysis class: `analysis.model.params`\n\n**Why This Order?**\nFlux is measured for continuous source, but neutron measurements use pulsed sources. The pulse_duration (from convolution) defines the pulsing duty cycle, which must be applied to the flux before Poisson sampling.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Workflow Features Summary\n\n**Key Methods**:\n- `.convolute(pulse_duration, bin_width=10)` - Apply instrument response\n- `.poisson(flux, freq, measurement_time, seed=None)` - Add Poisson noise\n- `.overlap(kernel, total_time=None, poisson_seed=None)` - Create frame overlap\n- `.reconstruct(kind='wiener', tmin=None, tmax=None, **kwargs)` - Deconvolve signal\n- `.analyze(xs='iron', vary_background=True, **kwargs)` - Fit with nbragg\n- `.plot()` - Visualize current state\n\n**Parameter Sweep Methods**:\n- `.sweep(param_name, values)` - Direct value specification\n- `.groupby(param_name, low, high, step/num)` - Range-based sweep\n- `.run(progress_bar=True)` - Execute sweep and return DataFrame\n\n**Sweep Features**:\n- Automatic tqdm progress bars (works in Jupyter and terminal)\n- Error handling - continues even if individual runs fail\n- Returns pandas DataFrame with all metrics\n- Includes: chi2, redchi2, AIC, BIC, all fitted parameters with errors\n\n**Use Cases**:\n1. **Quick processing**: Chain entire pipeline without intermediate variables\n2. **Parameter optimization**: Find best noise_power, pulse_duration, etc.\n3. **Sensitivity analysis**: Understand how parameters affect results\n4. **Batch processing**: Process multiple datasets with same pipeline",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Example 2: Study effect of pulse_duration\n# Using step parameter instead of num\nresults_pulse = (Workflow('iron_powder.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\n    .groupby('pulse_duration', low=100, high=300, step=50)\n    .convolute()  # pulse_duration comes from sweep\n    .poisson(flux=1e6, freq=60, measurement_time=30)\n    .overlap(kernel=[0, 25])\n    .reconstruct(kind='wiener', noise_power=0.01)\n    .analyze(xs='iron', vary_background=True, vary_response=True)\n    .run())\n\nprint(results_pulse[['pulse_duration', 'redchi2', 'aic']])\n\n# Plot\nresults_pulse.plot(x='pulse_duration', y='redchi2', marker='o', style='-o')\nplt.xlabel('Pulse Duration (µs)')\nplt.ylabel('Reduced χ²')\nplt.title('Effect of Pulse Duration on Fit Quality')\nplt.grid(True, alpha=0.3)\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Example 2: Explore Pulse Duration Effect",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Plot sweep results\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Chi-squared vs noise_power\nresults_noise.plot(x='noise_power', y='redchi2', marker='o', ax=axes[0])\naxes[0].axhline(y=1, color='gray', linestyle='--', alpha=0.5)\naxes[0].set_xlabel('Noise Power')\naxes[0].set_ylabel('Reduced χ²')\naxes[0].set_title('Fit Quality vs Noise Power')\naxes[0].grid(True, alpha=0.3)\naxes[0].legend().remove()\n\n# AIC vs noise_power (lower is better)\nresults_noise.plot(x='noise_power', y='aic', marker='s', color='orange', ax=axes[1])\naxes[1].set_xlabel('Noise Power')\naxes[1].set_ylabel('AIC (Akaike Information Criterion)')\naxes[1].set_title('Model Selection Criterion')\naxes[1].grid(True, alpha=0.3)\naxes[1].legend().remove()\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Example 1: Optimize noise_power\n# Sweep from 0.01 to 0.1 with 10 points\nresults_noise = (Workflow('iron_powder.csv', 'openbeam.csv', flux=5e6, duration=0.5, freq=20)\n    .convolute(pulse_duration=200)\n    .poisson(flux=1e6, freq=60, measurement_time=30)\n    .overlap(kernel=[0, 25])\n    .groupby('noise_power', low=0.01, high=0.1, num=10)  # or use step=0.01\n    .reconstruct(kind='wiener')\n    .analyze(xs='iron', vary_background=True, vary_response=True)\n    .run())  # Shows progress bar!\n\n# Results is a pandas DataFrame\nprint(results_noise.head())\n\n# Find optimal parameters\nbest = results_noise.loc[results_noise['redchi2'].idxmin()]\nprint(f\"\\n✓ Best noise_power: {best['noise_power']:.4f}\")\nprint(f\"✓ Best χ²/dof: {best['redchi2']:.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}